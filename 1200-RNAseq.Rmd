---
title: "1200-RNAseq"
author: "Mac Campbell"
date: "9/19/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning=FALSE)
```

```{r}
library(tidyverse)
```

## RNA seq

Method? Machine?  Tagseq?

Looks to be single end data (expected)     
`ls ../00-RawData/ | perl -pe 's/.fastq.gz//g' > all-samples.txt`     

Existing workflows?     
https://github.com/z0on/tag-based_RNAseq
https://github.com/ben-laufer/Tag-seq/blob/master/tag-seq.sh    

__0__ Building STAR indices
module  star/2.7.10a 

Using gtf to annotate (https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/021/917/145/GCF_021917145.1_fHypTra1/GCF_021917145.1_fHypTra1_genomic.gtf.gz)

Read length = 85, sjdbOverhand 85-1 = 84

```{sh, eval=FALSE}
module star/2.7.10a 
srun -p high --nodes=1 --time=4:00:00 STAR --runThreadN 4 --runMode genomeGenerate --genomeDir /home/maccamp/RNAseq/reference/ --genomeFastaFiles /home/maccamp/RNAseq/reference/GCF_021917145.1_fHypTra1_genomic.fna --sjdbGTFfile /home/maccamp/RNAseq/reference/GCF_021917145.1_fHypTra1_genomic.gtf --sjdbOverhang 84 > index.out 2>index.err &
```

__1__ Basic assessment

Calling like this:     

```{sh eval=FALSE}
sbatch -p med -J fastqc.$USER --array=1-12 01-fastqc.slurm;
sbatch -J mqcp.${USER} 01-pre-multiqc.slurm
```


__2__ Trimming

We need to accomodate for quite a bit. trimmomatic or bbmap/bbduk.sh are appropriate. Requires some references for trimming such as Illumina RNA seq adapters, etc.    module avail indicates we have bbmap/38-72                  

Examining data for adapter signatures.    
>TruSeq Universal Adapter						
AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT
>TruSeq Adapter, Index 1							
GATCGGAAGAGCACACGTCTGAACTCCAGTCACATCACGATCTCGTATGCCGTCTTCTGCTTG

```{sh, eval=FALSE}
gunzip -c AF104_UMI_S81_R1_001.fastq.gz | head -n 4000000 > temp.fastq
#HITS
#"GATCGGAAGAGCACACGTCTGAACTCCAGT", part of Truseq Adapter, index 1
#"AGATCGGAAGAGCACACGTCTGAACTCCAGTCA" Truseq forward
```

Adding these to trim
>TruSeq Universal Adapter						
AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT
>TruSeq Adapter, Index 1							
GATCGGAAGAGCACACGTCTGAACTCCAGTCACATCACGATCTCGTATGCCGTCTTCTGCTTG
>TruSeq Adapter, Index 2							
GATCGGAAGAGCACACGTCTGAACTCCAGTCACCGATGTATCTCGTATGCCGTCTTCTGCTTG
>TruSeq Adapter, Index 3							
GATCGGAAGAGCACACGTCTGAACTCCAGTCACTTAGGCATCTCGTATGCCGTCTTCTGCTTG
>TruSeq Adapter, Index 4							
GATCGGAAGAGCACACGTCTGAACTCCAGTCACTGACCAATCTCGTATGCCGTCTTCTGCTTG
>TruSeq Adapter, Index 5							
GATCGGAAGAGCACACGTCTGAACTCCAGTCACACAGTGATCTCGTATGCCGTCTTCTGCTTG
>TruSeq Adapter, Index 6							
GATCGGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG
>TruSeq Adapter, Index 7							
GATCGGAAGAGCACACGTCTGAACTCCAGTCACCAGATCATCTCGTATGCCGTCTTCTGCTTG
>TruSeq Adapter, Index 8							
GATCGGAAGAGCACACGTCTGAACTCCAGTCACACTTGAATCTCGTATGCCGTCTTCTGCTTG
>TruSeq Adapter, Index 9							
GATCGGAAGAGCACACGTCTGAACTCCAGTCACGATCAGATCTCGTATGCCGTCTTCTGCTTG
>TruSeq Adapter, Index 10						
GATCGGAAGAGCACACGTCTGAACTCCAGTCACTAGCTTATCTCGTATGCCGTCTTCTGCTTG
>TruSeq Adapter, Index 11						
GATCGGAAGAGCACACGTCTGAACTCCAGTCACGGCTACATCTCGTATGCCGTCTTCTGCTTG
>TruSeq Adapter, Index 12						
GATCGGAAGAGCACACGTCTGAACTCCAGTCACCTTGTAATCTCGTATGCCGTCTTCTGCTTG
>Truseq forward read
AGATCGGAAGAGCACACGTCTGAACTCCAGTCA
>Truseq reverse read
AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT

Trimming script 02-bbduk.slurm is this:
It has a poly-A workaround   https://www.biostars.org/p/236515/   
First 12bp also biased, but using STAR.     

```{sh, eval=FALSE}
#!/bin/bash
#
#SBATCH --time=4-00
#SBATCH --mem=10G # Memory pool for all cores (see also --mem-per-cpu)
#SBATCH --output=slurmout/bbduk-%A-%a.out # File to which STDOUT will be written
#SBATCH --error=slurmout/bbduk-%A-%a.err # File to which STDERR will be written

start=`date +%s`
hostname

aklog
export baseP=/home/$USER/RNAseq/
export seqP=${baseP}/00-RawData
export outP=${baseP}/02-Trimmed
export cwd=${baseP}/scripts
export tmpP=$cwd/tmp


if [ ! -d "${outP}" ]; then
   mkdir ${outP}
fi

if [ ! -d "${tmpP}" ]; then
   mkdir ${tmpP}
fi


module load bbmap/38-72   

name=`head -n ${SLURM_ARRAY_TASK_ID} allsamples.txt | tail -1`


call="bbduk.sh -t ${SLURM_NTASKS} \
in=$seqP/${name}.fastq.gz \
out=$outP/${name}.fastq.gz  \
ref=adapters.fasta \
literal=AAAAAAAAAAAAAAAAAA \
k=13 \
ktrim=r \
useshortkmers=t \
mink=5 \
qtrim=r \
trimq=10 \
minlength=20 \
stats=$outP/${name}-stats.txt"

echo $call
eval $call

end=`date +%s`
runtime=$((end - start ))
echo $runtime
```

call:
`sbatch -p med -J bbduk$USER --array=1-12 02-bbduk.slurm`   

__3__ Post-trim fastqc

```{sh, eval=FALSE}
#!/bin/bash
#
#SBATCH --time=2-00
#SBATCH --mem=10G # Memory pool for all cores (see also --mem-per-cpu)
#SBATCH --output=slurmout/fqc-post-%A-%a.out # File to which STDOUT will be written
#SBATCH --error=slurmout/fqc-post-%A-%a.err # File to which STDERR will be written

start=`date +%s`
hostname

aklog
export baseP=/home/$USER/RNAseq/
export seqP=${baseP}/02-Trimmed
export outP=${baseP}/03-fastqc-post
export cwd=${baseP}/scripts
export tmpP=$cwd/tmp


if [ ! -d "${outP}" ]; then
   mkdir ${outP}
fi

if [ ! -d "${tmpP}" ]; then
   mkdir ${tmpP}
fi


module load fastqc/0.11.9

name=`head -n ${SLURM_ARRAY_TASK_ID} allsamples.txt | tail -1`


call="fastqc -t ${SLURM_NTASKS} --dir $tmpP --outdir $outP $seqP/${name}.fastq.gz"
echo $call
eval $call

#call="fastqc -t ${SLURM_NTASKS} --dir $tmpP --outdir $outP $seqP/${name}-2.fastq"
#echo $call
#eval $call


end=`date +%s`
runtime=$((end - start ))
echo $runtime
```

Note:
`(base) maccamp@farm:~/RNAseq/scripts$ gunzip -c ../00-RawData/AF104_UMI_S81_R1_001.fastq.gz  | wc `      
15308648 19135810 881001287     
`(base) maccamp@farm:~/RNAseq/scripts$ gunzip -c ../02-Trimmed/AF104_UMI_S81_R1_001.fastq.gz | wc`     
15283580 19104475 855775669     

`sbatch -p med -J fqp-$USER --array=1-12 03-post-trim-fastqc.slurm`   

Dropped dependency, see Methylation for better way to do this.    
`sbatch -J mqcp.${USER} 03-post-trim-multiqc.slurm`


```{sh, eval=FALSE}
#!/bin/bash
#
#SBATCH --time=1-00
#SBATCH --mem=5G # Memory pool for all cores (see also --mem-per-cpu)
#SBATCH --partition=bigmemm  # Partition to submit to
#SBATCH --account=millermrgrp
#SBATCH --output=slurmout/mqcp-%j.out # File to which STDOUT will be written
#SBATCH --error=slurmout/mqcp-%j.err # File to which STDERR will be written

start=`date +%s`
hostname

aklog
export baseP=$HOME/RNAseq
export seqP=${baseP}/03-fastqc-post
export outP=${baseP}/03-multiqc-post
export cwd=${baseP}/scripts
export tmpP=$cwd/tmp


if [ ! -d "${outP}" ]; then
   mkdir ${outP}
fi

if [ ! -d "${tmpP}" ]; then
   mkdir ${tmpP}
fi


#module load multiqc/1.9
#module load bio3
module load multiqc/bio3    

call="multiqc -o $outP/ -f $seqP/*_fastqc.zip"
echo $call
eval $call


end=`date +%s`
runtime=$((end - start ))
echo $runtime

```

__4__ Align



```{sh, eval=FALSE}
#!/bin/bash
#
#SBATCH --time=4-00
#SBATCH --mem=10G # Memory pool for all cores (see also --mem-per-cpu)
#SBATCH --output=slurmout/star-%A-%a.out # File to which STDOUT will be written
#SBATCH --error=slurmout/star-%A-%a.err # File to which STDERR will be written


start=`date +%s`
hostname
#aklog
export baseP=/home/$USER/RNAseq/
export seqP=${baseP}/02-Trimmed
export outP=${baseP}/04-Align
export cwd=${baseP}/scripts
export tmpP=$cwd/tmp

if [ ! -d "${outP}" ]; then
   mkdir ${outP}
fi

if [ ! -d "${tmpP}" ]; then
   mkdir ${tmpP}
fi

name=`head -n ${SLURM_ARRAY_TASK_ID} allsamples.txt | tail -1`

module load star/2.7.10a 

call="STAR \
--runThreadN 4 \
--genomeDir /home/maccamp/RNAseq/reference/ \
--readFilesIn $seqP/${name}.fastq.gz  \
--readFilesCommand zcat \
--outFilterType BySJout \
--outFilterMultimapNmax 20 \
--alignSJoverhangMin 8 \
--alignSJDBoverhangMin 1 \
--outFilterMismatchNmax 999 
--outFilterMismatchNoverLmax 0.1 \
--alignIntronMin 20 \
--alignIntronMax 1000000 \
--alignMatesGapMax 1000000 \
--outSAMattributes NH HI NM MD \
--outSAMtype BAM SortedByCoordinate \
--outFileNamePrefix $outP/${name}- \
--quantMode GeneCounts"

echo $call
eval $call
```

`sbatch -p med -J star-$USER --array=1-12 04-star-align.slurm `

Don't forget to index bams!!    
`(base) maccamp@farm:~/RNAseq/04-Align$ for f in *.bam; do echo $f; samtools index $f; done;`


## DESeq2      

What were our samples again?     
Sample Well RIN      
29	E04	4.99   
106	B02	4.93   
91	C12	4.92   
49	A07	4.89   
36	D05	4.77   
27	C04	4.75   
104	H01	4.75   
51	C07	4.74   
94	F12	4.68    
108	D02	4.66    
39	G05	4.64    
26	B04	4.62    
    
```{r}
rin <-read_csv("meta/Sorted-RIN.csv")
meta<-read_csv("meta/dsm-rna-meta.csv")  %>% mutate(Sample=paste0("AF",`sonication number`)) %>% relocate(Sample)
```


```{r}
tops<-rin %>% head(n=12)
keepers <- filter(rin, rin$`Sample Name` %in% tops$`Sample Name`)
keepers<-keepers %>% mutate(Sample=paste0("AF", `Sample Name`)) %>% relocate(Sample)
keepers<-keepers %>% left_join(meta)
keepers$Category<-gsub("_\\w_","",keepers$`hdi category`)
keepers %>% arrange(Category) %>% select(Sample, Category)
```

Analyzing with DESeq2       
We need to have our counts matrix and col be in the same order     
Count matrix unstranded?     

Want something like
`gene_id\thdi1\thdi2\tldi1\tldi2\n`
```{sh, eval=FALSE}
for f in *.tab; do echo $f | perl -pe 's/_.*out.tab//g'; done;
```
AF104
AF106
AF108
AF26
AF27
AF29
AF36
AF39
AF49
AF51
AF91
AF94

Creating a function to do what I want.    

```{r}
dat<-read_tsv("outputs/1200/AF104_UMI_S81_R1_001-ReadsPerGene.out.tab", col_names = c("gene_id","Unstranded", "First Read","Second Read"))
dat
#TagSeq is strand specific, so `First Read` is what we want
```


```{r}
dat[startsWith(dat$gene_id, "N_"),]
```

```{r}
dat2<-dat[!startsWith(dat$gene_id, "N_"),]
dat2 %>% select(gene_id, `First Read`) %>% rename(AF104=`First Read`)
```

Now, do it 12 times real fast.     

```{r}
files<-list.files(path="outputs/1200/", pattern="*.tab")
files
samples<-gsub("_UMI.*.tab","",files)
samples
```

```{r}
getAmbiguities<-function(file) {
  dat<-read_tsv(paste0("outputs/1200/", file),
                col_names = c("gene_id","Unstranded", "First Read","Second Read"))     
  ambigs<-dat[startsWith(dat$gene_id, "N_"),]
  ambigs<-ambigs %>% select(gene_id, `First Read`) %>% rename(Count=`First Read`) %>% mutate(Sample=gsub("_UMI.*.tab","",file))
  return(ambigs)
}
```

```{r}
ambig<-bind_rows(lapply(files,getAmbiguities)) %>% group_by(Sample) %>% mutate(N_Total=sum(Count))
ambig
```

```{r}
readTab<-function(file) {
  dat<-read_tsv(paste0("outputs/1200/", file),
                col_names = c("gene_id","Unstranded", "First Read","Second Read"))     
  dat2<-dat[!startsWith(dat$gene_id, "N_"),]
  dat3<-dat2 %>% select(gene_id, `First Read`) %>% rename(Count=`First Read`) %>% mutate(Sample=gsub("_UMI.*.tab","",file))
  return(dat3)
}
```

```{r}
dat<-bind_rows(lapply(files,readTab))
dat
```


Summarize a bit.

```{r}
sum<-dat %>% group_by(Sample) %>% mutate(Total=sum(Count)) %>% select(Sample, Total) %>% unique()

ggplot(sum) + geom_histogram(aes(x=Total,fill=Sample)) +
  scale_fill_viridis_d(option = "turbo") +
  ylab("Count") +
  theme_bw()
```

Comparing to ambiguities.

```{r}
sum2<-sum %>% mutate(gene_id="Mapped to Feature") %>% mutate(N_Total=Total) %>% bind_rows(rename(ambig, Total=Count))
sum2
```

```{r}
comparisons<-sum2 %>% select(-N_Total) %>% pivot_wider(names_from = Sample, values_from=Total)
comparisons
write_csv(comparisons, "outputs/1200/comparison-post-alignment.csv")
```

Untidy the data and put columns in a sensible order.

```{r}
tsv<-dat %>% pivot_wider(names_from = Sample, values_from=Count)
tsv

order<-keepers %>% arrange(Category) %>% select(Sample, Category) %>% mutate(Type="TagSeq")
order
write_tsv(order, "outputs/1200/coldata.tsv")
```

```{r}
tsv2<-relocate(tsv, gene_id, order$Sample)
tsv2
write_tsv(tsv2, file="outputs/1200/pasilla_gene_counts.tsv")
```

```{r, eval=FALSE}
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("DESeq2")
```

```{r}
library(DESeq2)
```

```{r}
cts <- as.matrix(read.csv("outputs/1200/pasilla_gene_counts.tsv",sep="\t",row.names="gene_id"))
head(cts)
```

```{r}
coldata <- read.csv("outputs/1200/coldata.tsv",sep="\t", row.names=1)
coldata
```

Creating DESeq data set.      

```{r}
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design = ~ Category)
dds
```

filter out low counts.      

```{r}
keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep,]
```

```{r}
dds <- DESeq(dds)
res <- results(dds)
res
```

```{r}
resOrdered <- res[order(res$pvalue),]
```

```{r}
summary(res)
```

```{r}
sum(res$padj < 0.1, na.rm=TRUE)
```


```{r}
res05 <- results(dds, alpha=0.05)
summary(res05)
```

```{r}
sum(res05$padj < 0.05, na.rm=TRUE)
```


Filtering for padk <0.05 and LFC >= 1

```{r}
results<-as_tibble(resOrdered)
results$Gene<-rownames(resOrdered)
results<-results %>% relocate(Gene) %>% filter(padj<0.05, abs(log2FoldChange) >= 1)
results
write_csv(results, "outputs/1200/results.csv")
```

Check counts for a couple.

```{r}
tsv2 %>% filter(gene_id %in% c("lum","rrad","irf5"))
```


## Reduce numbers to 1/4 or 1/2 of what there is and see what DE's turn up?

```{r}
cts4<-round(cts/2,0)
head(cts4)
```


```{r}
dds <- DESeqDataSetFromMatrix(countData = cts4,
                              colData = coldata,
                              design = ~ Category)
dds

keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep,]

dds <- DESeq(dds)
res <- results(dds)
res
```

```{r}
resOrdered <- res[order(res$pvalue),]
```

```{r}
summary(res)
sum(res$padj < 0.1, na.rm=TRUE)
```

Reduced number of DE genes from 1501 to 724 with 1/2 the data, 293 with 1/4 the data. 

```{r}
results<-as_tibble(resOrdered)
results$Gene<-rownames(resOrdered)
results<-results %>% relocate(Gene) %>% filter(padj<0.05, abs(log2FoldChange) >= 1)
results
```